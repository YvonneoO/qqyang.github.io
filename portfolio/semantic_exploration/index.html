<!doctype html><html lang="en" class="no-js"><head><meta charset="utf-8"> <!-- begin SEO --><title>Semantic Exploration and Dense Mapping with Panoramic LiDAR–Camera Fusion - Qianqian Yang’s Homepage</title><meta property="og:locale" content="en-US"><meta property="og:site_name" content="Qianqian Yang's Homepage"><meta property="og:title" content="Semantic Exploration and Dense Mapping with Panoramic LiDAR–Camera Fusion"><link rel="canonical" href="https://qq-yang.com/portfolio/semantic_exploration/"><meta property="og:url" content="https://qq-yang.com/portfolio/semantic_exploration/"><meta property="og:description" name="description" content="An integrated framework for semantic exploration and dense object-level mapping using panoramic LiDAR–camera fusion on a legged robot. "> <!-- end SEO --><link href="https://qq-yang.com/feed.xml" type="application/atom+xml" rel="alternate" title="Qianqian Yang's Homepage Feed"> <!-- http://t.co/dKP3o1e --><meta name="HandheldFriendly" content="True"><meta name="MobileOptimized" content="320"><meta name="viewport" content="width=device-width, initial-scale=1.0"> <script> document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js '; </script> <!-- For all browsers --><link rel="stylesheet" href="https://qq-yang.com/assets/css/main.css"><meta http-equiv="cleartype" content="on"> <!-- start custom head snippets --><link rel="apple-touch-icon" sizes="57x57" href="https://qq-yang.com/images/apple-touch-icon-57x57.png?v=M44lzPylqQ"><link rel="apple-touch-icon" sizes="60x60" href="https://qq-yang.com/images/apple-touch-icon-60x60.png?v=M44lzPylqQ"><link rel="apple-touch-icon" sizes="72x72" href="https://qq-yang.com/images/apple-touch-icon-72x72.png?v=M44lzPylqQ"><link rel="apple-touch-icon" sizes="76x76" href="https://qq-yang.com/images/apple-touch-icon-76x76.png?v=M44lzPylqQ"><link rel="apple-touch-icon" sizes="114x114" href="https://qq-yang.com/images/apple-touch-icon-114x114.png?v=M44lzPylqQ"><link rel="apple-touch-icon" sizes="120x120" href="https://qq-yang.com/images/apple-touch-icon-120x120.png?v=M44lzPylqQ"><link rel="apple-touch-icon" sizes="144x144" href="https://qq-yang.com/images/apple-touch-icon-144x144.png?v=M44lzPylqQ"><link rel="apple-touch-icon" sizes="152x152" href="https://qq-yang.com/images/apple-touch-icon-152x152.png?v=M44lzPylqQ"><link rel="apple-touch-icon" sizes="180x180" href="https://qq-yang.com/images/apple-touch-icon-180x180.png?v=M44lzPylqQ"><link rel="icon" type="image/png" href="https://qq-yang.com/images/favicon-32x32.png?v=M44lzPylqQ" sizes="32x32"><link rel="icon" type="image/png" href="https://qq-yang.com/images/android-chrome-192x192.png?v=M44lzPylqQ" sizes="192x192"><link rel="icon" type="image/png" href="https://qq-yang.com/images/favicon-96x96.png?v=M44lzPylqQ" sizes="96x96"><link rel="icon" type="image/png" href="https://qq-yang.com/images/favicon-16x16.png?v=M44lzPylqQ" sizes="16x16"><link rel="manifest" href="https://qq-yang.com/images/manifest.json?v=M44lzPylqQ"><link rel="mask-icon" href="https://qq-yang.com/images/safari-pinned-tab.svg?v=M44lzPylqQ" color="#000000"><link rel="shortcut icon" href="/images/favicon.ico?v=M44lzPylqQ"><meta name="msapplication-TileColor" content="#000000"><meta name="msapplication-TileImage" content="https://qq-yang.com/images/mstile-144x144.png?v=M44lzPylqQ"><meta name="msapplication-config" content="https://qq-yang.com/images/browserconfig.xml?v=M44lzPylqQ"><meta name="theme-color" content="#ffffff"><link rel="stylesheet" href="https://qq-yang.com/assets/css/academicons.css"/> <!-- Support for MatJax --> <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> <!-- end custom head snippets --></head><body> <!--[if lt IE 9]><div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div><![endif]--><div class="masthead"><div class="masthead__inner-wrap"><div class="masthead__menu"><nav id="site-nav" class="greedy-nav"> <button><div class="navicon"></div></button><ul class="visible-links"><li class="masthead__menu-item masthead__menu-item--lg"><a href="https://qq-yang.com/">Qianqian Yang's Homepage</a></li><li class="masthead__menu-item"><a href="https://qq-yang.com/publications/">Publications</a></li><li class="masthead__menu-item"><a href="https://qq-yang.com/portfolio/">Portfolio</a></li><li class="masthead__menu-item"><a href="https://qq-yang.com/cv/">CV</a></li></ul><ul class="hidden-links hidden"></ul></nav></div></div></div><div id="main" role="main"><div class="sidebar sticky"><div itemscope itemtype="http://schema.org/Person"><div class="author__avatar"> <img src="https://qq-yang.com/images/avatar/1.jpg" class="author__avatar" alt="Qianqian Yang"></div><div class="author__content"><h3 class="author__name">Qianqian Yang</h3><p class="author__bio">MSME-R @ CMU</p></div><div class="author__urls-wrapper"> <button class="btn btn--inverse">Follow</button><ul class="author__urls social-icons"> <!-- Font Awesome icons / Biographic information --><li class="author__desktop"><i class="fa-solid fa-location-dot icon-pad-right" aria-hidden="true"></i>Earth</li><li class="author__desktop"><i class="fas fa-fw fa-building-columns icon-pad-right" aria-hidden="true"></i>Carnegie Mellon University</li><li><a href="mailto:qianqiay@andrew.cmu.edu"><i class="fas fa-fw fa-envelope icon-pad-right" aria-hidden="true"></i>Email</a></li><!-- Font Awesome and Academicons icons / Academic websites --> <!-- Font Awesome icons / Repositories and software development --><li><a href="https://github.com/YvonneoO"><i class="fab fa-fw fa-github icon-pad-right" aria-hidden="true"></i>Github</a></li><!-- Font Awesome icons / Social media --><li><a href="https://www.linkedin.com/in/qianqian-yang-b06591200"><i class="fab fa-fw fa-linkedin icon-pad-right" aria-hidden="true"></i>LinkedIn</a></li></ul></div></div></div><article class="page" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="headline" content="Semantic Exploration and Dense Mapping with Panoramic LiDAR–Camera Fusion"><meta itemprop="description" content="An integrated framework for semantic exploration and dense object-level mapping using panoramic LiDAR–camera fusion on a legged robot. "><div class="page__inner-wrap"><header><h1 class="page__title" itemprop="headline">Semantic Exploration and Dense Mapping with Panoramic LiDAR–Camera Fusion</h1></header><section class="page__content" itemprop="text"><h2 id="introduction">Introduction</h2><p>This project presents a <strong>complete semantic exploration and dense mapping framework</strong> that enables a ground robot to autonomously explore, detect, and reconstruct target objects in large unknown environments.</p><p>The robot fuses panoramic camera and LiDAR data to build <strong>object-level dense semantic maps</strong>, integrating viewpoint planning and multi-view fusion to improve mapping completeness and accuracy.</p><p>Unlike conventional exploration strategies focused on free-space coverage, our approach explicitly considers <strong>semantic targets</strong> and <strong>object-level observation planning</strong>, balancing exploration efficiency and reconstruction quality.</p><figure style="text-align: center;"> <img src="../../images/semantic_exploration/Lobby_overall_result.png" alt="Lobby overall mapping result" style="max-width: 100%; margin: 0 auto;" /><figcaption style="font-style: italic;">Figure 1 – Dense semantic mapping result in lobby environment</figcaption></figure><hr /><h2 id="system-overview">System Overview</h2><p>The framework consists of four main modules — <strong>Mapping</strong>, <strong>Local Sampler</strong>, <strong>Global Planner</strong>, and <strong>Safe-Aggressive Exploration Safe Machine</strong> — operating in a closed exploration loop.<br /> The robot incrementally constructs a semantic map, samples informative viewpoints, plans exploration paths, and executes them safely while maintaining consistent mapping and localization.</p><figure style="text-align: center; margin-bottom: 20px;"> <img src="../../images/semantic_exploration/System_overview.png" alt="System overview of semantic exploration and mapping" style="max-width: 100%; margin: 0 auto;" /><figcaption style="font-style: italic;">Figure 2 – Overview of the semantic exploration framework with four modules: Mapping, Sampler, Planning, and Safe Machine</figcaption></figure><h3 id="key-components">Key Components</h3><ul><li><strong>Mapping:</strong> Builds a real-time dense voxel map with LiDAR–camera fusion and semantic object reconstruction.</li><li><strong>Local Sampler:</strong> Generates viewpoint candidates around exploration frontiers and object surfaces to maximize information gain.</li><li><strong>Global Planner:</strong> Selects and sequences viewpoints using an ATSP-based global planner and PRM-based local path search.</li><li><strong>Safe Machine:</strong> Monitors collision risks, invalid states, and execution stability to ensure safe and continuous operation.</li></ul><h3 id="my-contribution">My Contribution</h3><ul><li><strong>LiDAR–Camera Registration:</strong> Extrinsic calibration and time-synchronized fusion between an Ouster LiDAR and panoramic camera (C++ / ROS1).</li><li><strong>Semantic Mapping:</strong> YOLO + SAM2 segmentation to produce labeled point clouds and voxel-based object maps.</li><li><strong>Coarse-to-Fine Reconstruction:</strong> Object model update, merging, and re-centering strategies ensure consistent, complete dense models.</li><li><strong>Multi-View Integration:</strong> Fuses observations from different viewpoints to reduce occlusion and sensor noise.</li></ul><div style="text-align: center; margin: 20px 0;"> <iframe width="640" height="360" src="https://www.youtube.com/embed/MU2Ksfzyac8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><p style="font-style: italic;">Video 1 – LiDAR–camera registration and fusion demonstration</p></div><hr /><h2 id="benchmark-results">Benchmark Results</h2><p>The exploration planner achieves significantly higher efficiency compared to traditional methods by prioritizing regions with semantic value and minimizing redundant motion.</p><figure style="text-align: center;"> <img src="../../images/semantic_exploration/benchmark_vis.png" alt="Benchmark comparison" style="max-width: 100%; margin: 0 auto;" /><figcaption style="font-style: italic;">Figure 3 – Benchmark of semantic exploration planning efficiency</figcaption></figure><ul><li>Exploration time reduced by <strong>&gt;40%</strong> compared to baseline planners</li><li>Viewpoint coverage improved by <strong>~30%</strong> for semantic targets</li><li>Ensured full dense reconstruction in large-scale industrial environments</li></ul><hr /><h2 id="real-world-results">Real-World Results</h2><p>The framework was validated in real-world construction and lobby environments.<br /> It successfully reconstructed complex, cluttered scenes with high semantic consistency and sub-centimeter accuracy.</p><p>Quantitative evaluation of the reconstructed maps was conducted on two environments. comparing both whole-map and object-level results. Metrics include map completeness, mean distance, and standard deviation of geometric alignment against ground truth.</p><table style="text-align:center;"><thead><tr><th rowspan="2">Environment</th><th rowspan="2">Map Type</th><th>Completeness</th><th>Mean Dist (m)</th><th>Std (m)</th></tr></thead><tbody><tr><td rowspan="2"><em>Construction Site</em></td><td>Whole Map</td><td>99.65%</td><td>0.0227248</td><td>0.0651594</td></tr><tr><td>Object Map</td><td>87.03%</td><td>0.0310901</td><td>0.0413562</td></tr><tr><td rowspan="2"><em>Lobby</em></td><td>Whole Map</td><td>99.72%</td><td>0.0050834</td><td>0.0048516</td></tr><tr><td>Object Map</td><td>97.22%</td><td>0.0175095</td><td>0.0231272</td></tr></tbody></table><p style="font-style:italic; text-align:center; margin-top: 8px;"> Table 1 – Statistical evaluation of real-world dense reconstruction results.</p><figure style="text-align: center;"> <img src="../../images/semantic_exploration/Construction_overall_result.png" alt="Construction mapping result" style="max-width: 100%; margin: 0 auto;" /><figcaption style="font-style: italic;">Figure 4 – Dense semantic reconstruction in a construction site environment</figcaption></figure><figure style="text-align: center;"> <img src="../../images/semantic_exploration/Lobby_error_compare.png" alt="Lobby mapping comparison" style="max-width: 100%; margin: 0 auto;" /><figcaption style="font-style: italic;">Figure 5 – Mapping error comparison in lobby environment</figcaption></figure><div style="text-align: center; margin: 20px 0;"> <iframe width="640" height="360" src="https://www.youtube.com/embed/p6s3XRHefNk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><p style="font-style: italic;">Video 2 – Final semantic exploration and mapping demonstration</p></div><hr /><h2 id="related-publication">Related Publication</h2><p><a href="https://ieeexplore.ieee.org/document/11159179">Semantic Exploration and Dense Mapping of Complex Environments using Ground Robot with Panoramic LiDAR–Camera Fusion (IEEE RA-L 2025)</a></p></section><footer class="page__meta"></footer><section class="page__share"><h4 class="page__share-title">Share on</h4><a href="https://twitter.com/intent/tweet?text=https://qq-yang.com/portfolio/semantic_exploration/" class="btn btn--twitter" title="Share on Twitter"><i class="fab fa-twitter" aria-hidden="true"></i><span> Twitter</span></a> <a href="https://www.facebook.com/sharer/sharer.php?u=https://qq-yang.com/portfolio/semantic_exploration/" class="btn btn--facebook" title="Share on Facebook"><i class="fab fa-facebook" aria-hidden="true"></i><span> Facebook</span></a> <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://qq-yang.com/portfolio/semantic_exploration/" class="btn btn--linkedin" title="Share on LinkedIn"><i class="fab fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a></section><nav class="pagination"> <a href="https://qq-yang.com/portfolio/robot_arm/" class="pagination--pager" title="3 DOF Robot Arm Demo ">Previous</a> <a href="https://qq-yang.com/portfolio/spot_window_frame_demo/" class="pagination--pager" title="LiDAR-Based Construction Progress Monitoring with Spot Quadruped ">Next</a></nav></div></article></div><div class="page__footer"><footer> <!-- start custom footer snippets --> <a href="/sitemap/">Sitemap</a> <!-- end custom footer snippets --><div class="page__footer-follow"><ul class="social-icons"><li><strong>Follow:</strong></li><li><a href="http://github.com/YvonneoO"><i class="fab fa-github" aria-hidden="true"></i> GitHub</a></li><li><a href="https://qq-yang.com/feed.xml"><i class="fa fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li></ul></div><!--<div class="page__footer-copyright"> &copy; 2025 Qianqian Yang, Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://github.com/academicpages/academicpages.github.io">AcademicPages</a>, a fork of <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.<br /> Site last updated 2025-10-10</div>--></footer></div><script src="https://qq-yang.com/assets/js/main.min.js"></script></body></html>
